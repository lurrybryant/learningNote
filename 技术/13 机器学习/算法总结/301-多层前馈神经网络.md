## 深度学习：
  《Deep learning》， Yoshua Bengio&Ian Goodfellow ，深度学习原理
  深度学习（含笔记）， Ng，
  《深度学习基础教程》，ng，深度学习原理
  《深度学习ppt》
  《深度学习500问》
  《百面深度学习》
  《Tensorflow实战谷歌深度学习框架》
  《21个项目玩转深度学习：基于TensorFlow的实践详解》
  《Hands-On Machine Learning with Scikit-Learn and TensorFlow》

深度学习：https://www.leiphone.com/news/201608/7lwVZCXnScbQb6cJ.html
深度学习tf：https://www.zhihu.com/question/41667903?from=profile_question_card


人工智能  
  如何将非形式化的知识传递给计算机；
    知识库方法：难以自己从原始数据中提取模式；
    机器学习：依赖数据的表示；特征的选取；
    表示学习：发现很好的特征集；比如自编码器。
    符号机器学习：统计机器学习；深度学习
  深度学习  
    通过较简单的概念构造复杂的概念；学习数据的正确表示    
      前馈深度网络；  
      多层感知机MLP；
      深度：计算图的深度和概率模型图的深度；
      深度学习是通往人工智能的途径；使计算机系统从经验和数据中得到提高；
      人工智能->机器学习->表示学习->深度学习
    发展：控制论（感知机） 联结主义（反向传播，并行分布处理） 深度学习；
      基本原理：多层次组合而不仅仅是神经科学观点；
      权重训练：随机梯度下降SGD
      线性模型不能学习异或；
      神经单元模型：RLU 整流线性单元
      计算神经科学独立于深度学习；
      分布式表示；
      长短期模型LSTM;
      无监督学习和小数据集上的泛化能力；
      序列到序列建模：机器翻译：RNN
      深度学习应用到强化学习（通过试错来学习执行任务）
      SVM将手写数字识别错误率降低到0.8%
      要求：计算性能强，数据量大，
      DNN：深层神经网络

三次浪潮
  40s-60s初：控制论（线性模型缺陷：无法学习XOR运算）
  80s-90s：从符号推理到连接主义（人工神经网络，神经科学观点）
    逆向大脑背后的计算原理 
    理解大脑和人类智能背后的原理
    中心思想：当网络将大量简单的计算单元连接在一起时可以实现智能行为。 
    概念：分布式表示，反向传播 ，长短期记忆 
  21世纪初：深度学习（2006年，学习多层次组合 ）
    深度学习领域主要关注如何构建计算机系统，从而成功解决需要智能才能解决的任务
    计算神经科学领域主要关注构建大脑如何真实工作的比较精确的模型。
    新的无监督学习技术和深度模型在小数据集的泛化能力，为此我们应特别侧重于如何通过无监督或半监督学习充分利用大量的未标注样本。 
    特点：
      与日俱增的数据量、计算能力
      与日俱增的模型规模 
      改进的训练算法
      与日俱增的精度、复杂度（序列建模和强化学习）和对现实世界的冲击
      在实践中，人工神经网络的一些理论局限性是良性的
      资金和进步的良性循环

学习能力
  抽象和形式化的任务，计算机强于人类
  直观而非形式化的任务，人类强于计算机
  如何将非形式化的知识传递给计算机
    知识库方法：难以自己从原始数据中提取模式；
    机器学习：依赖数据的表示，特征的选取；
    表示学习：发现很好的特征集，比如自编码器。
    深度学习
      机器学习&表示学习&深度学习
      机器学习依赖数据的表示（冗余数据和无关数据干扰），很难知道提取哪些特征
      表示学习可以学习到数据的表示（真正能解释观察数据的变差因素）
      深度学习通过简单表示来表达复杂表示（深度促使计算机学习一个多步骤的计算机程序）
      深度学习是通往人工智能的途径之一，是机器学习的一种。它将大千世界表示为嵌套的层次概念体系



前向神经网络：
   Hopfield网络，
   自组织映射（Self-Organizing Map, SOM），
   深度玻尔兹曼机DBM，
   受限波尔兹曼机（Restricted Boltzmann Machine， RBN），
   伯努利限制玻尔兹曼机，
   Deep Belief Networks（DBN），
   深度神经网络DNN，
   分层时间记忆HTM，
   极端学习机ELM，
   逻辑学习机LLM，
   尖峰神经网络，
   RBFN，RBF网络，
   ART网络，
   级联相关网络，
   Elman网络，
   Random Neural Networks
   概率神经网络PNN
   对向传播神经网络（CPN）
   贝叶斯神经网络
M-P神经元模型，感知机
人工神经网络（ANN）
通用性、强大性和可扩展性
RBF网络：激活函数是径向基函数
ART网络：竞争型网络、结构自适应网络
SOM网络：竞争型网络
级联相关网络：结构自适应网络
Elman网络：递归神经网络
Boltzman机：基于能量的模型、递归神经网络SS
限制Boltzman机：
深度信念网络：多个RBM堆叠
改善神经网络的可解释性：从神经网络中抽取易于理解的符号规则



前馈神经网络（MLP）：图像
循环神经网络（RNN）：文本
相关问题？
  深度or宽度
  为什么深层而不是浅层？
  深度神经网络的这许多隐藏层中，较早的前几层能学习一些低层次的简单特征，等到后几层，就能把简单的特征结合起来，去探测更加复杂的东西。
  深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的
计算结果则需要指数级增长的单元数量才能达到。
前馈网络加入非线性变换，克服线性模型的局限性
为什么需要非线性激活函数？
  因为两个线性函数的组合本身就是线性函数，所以除非你引入非线性，否则你无法计算更有趣的函数
  如何选择映射𝜑？通用的变换泛化性能不佳，手动的变换很难迁移，函数族中学习出精确的映射



设计决策？
  优化模型
  代价函数
  输出单元
  隐藏单元
  网络结构
    举例：XOR函数的学习
    多层感知机表示异或逻辑时最少需要几个隐含层(仅考虑二元输入)?
    如果只使用一个隐层，需要多少隐节点能够实现包含n元输入的任意布尔函数?
    考虑多隐层的情况，实现包含n元输入的任意布尔函数最少需要多少个网络节点和网络层?
三要素：激活函数、特征线性组合、决策层

基于梯度的学习
  代价函数
    神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸
    用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感 
    代价函数的梯度必须足够的大且具 有足够的预测性 
    均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。 
    为何平方损失函数不适合最后一层含有Sigmoid或Softmax激活函数的神经网络呢?可以回顾上一问推导出的平方误差损失函数相对于输出层的导数，函数的梯度会趋于饱和，即绝对值非常小，导致δ(L)的取值
也非常小，使得基于梯度的学习速度非常缓慢。

  输出单元
    用于高斯输出分布的线性单元 ：不会饱和，易于采用基于梯度的优化算法，均方误差损失
    用于 Bernoulli 输出分布的 sigmoid 单元 ，损失函数为最大似然
    用于 Multinoulli 输出分布的 softmax 单元 ， softmax 函数提供了 argmax 的 ‘‘软化’’ 版本 
    其他的输出类型 ：高斯混合模型

  隐藏单元
    常用激活函数及其导数
    如何选择激活函数？试错。
      整流线性单元 ：
        缺陷：它们不能通过基于梯度的方法学习那些使它们激活为零的样本。导致神经元死亡的问题。这是由于函数 导致负梯度在经过该ReLU单元时被置为0，且在之后也不被任何数
据激活，即流经该神经元的梯度永远为0，不对任何数据产生响应。在实际训练 中，如果学习率(Learning Rate)设置较大，会导致超过一定比例的神经元不可逆 死亡，进而参数梯度无法更新，整个训练过程失败。
        优点：快速计算梯度；没有最大输出值的事实也有助于减少梯度下降期间的一些问题（比如梯度消失，学习得更快 ）。ReLU的单侧抑制提供了网络的稀疏表达能力。
        扩展：  g(z, α)i = max(0, zi) + αimin(0, zi) parametric ReLU ， absolute value rectification ， Leaky ReLU ， maxout unit，另一个LReLU的变种增加了“随机化”机制，具体 地，在训练过程中，斜率a作为一个满足某种分布的随机采样;测试时再固定下来。Random ReLU(RReLU)在一定程度上能起到正则化的作用。
      双曲正切激活函数 ： tanh(z) = 2σ(2z) − 1 。
        优点：使每个层的输出在训练开始时或多或少都正则化了（即以 0 为中心），有助于加快收敛速度；
      Sigmoid激活函数： sigmoid单元的广泛饱和性会使得基于梯度的学习变得非常困难。在𝑧特别大或者特别小的情况下，导数的梯度或者函数的斜率会变得特别小，最后就会接近于 0，导致降低梯度下降的速度 。 sigmoid 激活函数在除了前馈网络以外的情景中更为常见。循环网络、许多概率模型以及一些自编码器有一些额外的要求使得它们不能使用分段线性激活函数 
        Sigmoid和Tanh激活函数会导致梯度消失的现象?
      线性隐藏单元：提供了一种减少网络中参数数量的有效方法 
      硬双曲正切函数(hard tanh) ，softplus函数 ，径向基函数(radial basis function, RBF) 

  网络结构
    万能近似定理(universal approximation theorem)(Hornik et al., 1989; Cybenko, 1989) 表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何 一种 ‘‘挤压’’ 性质的激活函数(例如logistic sigmoid激活函数)的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的 Borel 可测函数。 
    单层：可能大得不可实现；可能无法正确地学习和泛化。深层：减少表示期望函数所需的单元的数量；减少泛化误差 
    如何将层与层之间连接起来 

  模型优化
    反向传播和其他的微分算法 
    找到完美的神经元数量仍然是黑色的艺术




正则化
  对学习算法的修改——旨在减少泛化误 差而不是训练误差
  数据集增强：向输入（隐藏层、参数、输出）注入噪声 ，创建假数据并 添加到训练集中，数据变换 
  参数范数惩罚。正则化解决欠定问题，伪逆；作为约束的范数惩罚。
  参数共享(parameter sharing)。和正则化参数使其接近(通过范数惩罚)相比，参数共享的一个显著优点是：只有参数(唯一一个集 合)的子集需要被存储在内存中。对于某些特定模型，如卷积神经网络，这可能可以显著减少模型所占用的内存 。降低了CNN模型的参数数量，并显著提高了网络的大小而不需要 相应地增加训练数据 
  集成平均至少与 它的任何成员表现得一样好，并且如果成员的误差是独立的，集成将显著地比其成 员表现得更好 ；Boosting。
  提前终止。
  稀疏化激活单元：对表示元素的 L1 惩罚诱导 。其他方法还包括 ：从表示上的Student-t 先验导出的惩罚 和KL 散度惩罚，还有一些其他方法通过激活值的硬性约束来获得表示稀疏 。
  Dropout：乘零；从网络中移除单元，权重比例推断规则，与bagging的区别和联系。为什么Dropout可以抑制过拟合?它的工作原理和实现?对于任意神经元，每次训练中都与一组随机挑选的不同的神经元集合共同进行优化，这个过程会减弱全体神经元之间的联合适应 性，减少过拟合的风险，增强泛化能力。
  批量归一化的基本动机与原理是什么?在卷积神经网络中如何使用?然而随着网络训练的进行，每个隐层的参数变化使得后一层的输入发生变 化，从而每一批训练数据的分布也随之改变，致使网络在每次迭代中都需要拟合不同的数据分布，增大训练的复杂度以及过拟合的风险。批量归一化方法是针对每一批数据，在网络的每一层输入之前增加归一化处 理(均值为0，标准差为1)，将所有批数据强制在统一的数据分布下。对数据的分布进行额外的约束，从而增强模型的泛化能力。但是批量归一化同时也降低了模型的拟合能力，归一化之后的输入分布被强制为0均值和1标准 差。以Sigmoid激活函数为例，批量归一化之后数据整体处于函数的非饱和区域， 只包含线性变换，破坏了之前学习到的特征分布。为了恢复原始数据分布，具体 实现中引入了变换重构以及可学习参数γ和β，对于一般的网络，不采用批量归 一化操作时，这两个参数高度依赖前面网络学习到的连接权重(对应复杂的非线 性)。而在批量归一化操作中，γ和β变成了该层的学习参数，仅用两个参数就可 以恢复最优的输入数据分布，与之前网络层的参数解耦，从而更加有利于优化的 过程，提高模型的泛化能力。
  批量归一化在卷积神经网络中应用时，需要注意卷积神经网络的参数共享机 制。每一个卷积核的参数在不同位置的神经元当中是共享的，因此也应该被一起 归一化。具体实现中，假设网络训练中每一批包含b个样本，由一个卷积核生成的 特征图的宽高分别为w和h，则每个特征图所对应的全部神经元个数为b×w×h;利 用这些神经元对应的所有输入数据，我们根据一组待学习的参数γ和β对每个输入 数据进行批量归一化操作。如果有f个卷积核，就对应f个特征图和f组不同的γ和β参 数。


优化算法
  与纯优化的区别
    机器学习通常是间接作用的，最小化训练集上的期望损失；训练算法通常不会 停止在局部极小点 ；机器学习算法的目标函数通常可以分解为训练样本上的求和 
    在使用一个非常大的训练集时，过拟合不再是问题，而欠拟合和计算效率变成了主要的顾虑 
  挑战
     病态： Hessian矩阵 H 的病 态 。病态体现在随机梯度下降会 ‘‘卡’’ 在某些情况，此时即使很小的更新步长也会增加代价函数。 
     局部极小值 ：非凸；不可辨识性：如果一个足够大的训练集可以唯 一确定一组模型参数，那么该模型被称为可辨认的。 ；一种能够排除局部极小值是主要问题的检测方法是画出 梯度范数随时间的变化。如果梯度范数没有缩小到一个微小的值，那么该问题既不 是局部极小值，也不是其他形式的临界点。 
     高原、鞍点和其他平坦区域 ：鞍点附近的某些点比鞍点有更大的代价，而其他点则有更 小的代价。在鞍点处，Hessian 矩阵同时具有正负特征值。位于正特征值对应的特征 向量方向的点比鞍点有更大的代价，反之，位于负特征值对应的特征向量方向的点 有更小的代价。我们可以将鞍点视为代价函数某个横截面上的局部极小点，同时也 可以视为代价函数某个横截面上的局部极大点。高维空 间中，局部极小值很罕见，而鞍点则很常见。当我们到达代价较低的区间时，Hessian 矩阵 的特征值为正的可能性更大。 真实的神经网络中也存在包含很多高代价鞍点的损失函数。一阶信息训练可以逃离鞍点。牛顿法不能替代一阶方法。极大值也指数减少，梯度法不会吸引到极大值。牛顿法寻找梯度为0的点。平坦区域。
     悬崖和梯度爆炸：由于几 个较大的权重相乘导致 ；启发式 梯度截断 。梯 度消失与爆炸问题 ，指该计算图上的 梯度也会因为 diag(λ)t 大幅度变化。循环网络在各时间步上使用相同的矩阵 W，而前馈网络并没有。因而即使是非 常深层的前馈网络也能一定程度上避免梯度消失与爆炸问题 (Sussillo, 2014)。 
     非精确梯度 ： 噪声；对比散度是用来近似玻尔兹曼机中难以处理的对数似然梯度的一种技术。 
     局部和全局结构间的弱对应 ：梯度下降和基本上所有的可以有效训练神经网络的学习算法，都是基于局部较 小更新。 
     优化的理论限制 ：我们为神经网络设计的任何优化算法都有性能限制 

基本算法
  SGD，学习过程可能会比较慢
  Momentum，动量方法，加速学习
  AdaGrad，AdaDelta，自适应学习率 
  RMSProp ，
  Adam，
  Ftrl，Nesterov 
参数初始化策略
  初始化模型的权重为高斯或均匀分布中随机抽取的值，且值比较小，避免梯度消失or爆炸。初始化参数为取值范围的均匀分布，其中d是一个神经
元接受的输入维度。偏置可以被简单地设为0，并不会导致参数对称的问题。
  参数为什么不能都初始化为0。梯度下降将不会起作用：如果你要初始化成0，由于所有的隐含单元都是对称的，无论你运行梯度下降多久，他们一直计算同样的函数。这没有任何帮助，因为你想要两个不同的隐含单元计算不同的函数，这个问题的解决方法就是随机初始化参数。倾向于初始化为很小的随机数。

关于局部最优和全局最优，策略：
  以多组不同的初值初始化。
  模拟退火
  随机梯度下降











