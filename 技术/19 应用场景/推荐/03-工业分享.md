## 知识收获
## 落地思考
1. 多任务模型
知乎推荐也ranking模型
YouTube多目标解决位置偏差问题
MMoE/ESMM/PLE
MMoE+ESSM PLE+ESMM+Attention
XGB样本采样/单模型加权/多模型独立学习/单模型hard share联合训练/soft share调优
GAUC？
一侧未充分训练：5种优化手段？
权重动态调整：不确定性权重、动态人去优先、动态权重平均、gardnorm、PCGrad
gradient surgery for multi-task learning

多目标在线融合方式：
加权融合、二阶段模型训练

2. embedding
其它算法：MF
bert+lstm：对用户行为序列建模
深度树匹配：TDM
长期和短期兴趣建模：SDM NIRSA
Graph Embedding：EGES Graphsage GAT
多embedding召回：MIND CrossTag
单embedding向量召回：YouTube DSSM
i2i召回、u2i召回、增量聚类群召回、动态规则聚类召回
airbnb：分群embedding、用户和item混合训练
离散值embedding：FM word2vec Hash nn.embedding_lookup
连续值：XGB+LR  分桶->emb
多值：max-pooling(FGCNN) avg-pooling（SENet） sum-pooling(DIN NFM CIN)
缺点：长尾数据难训练、很难同时包含多个特征、增量更新的语义不变性、空间分布影响模型的泛化误差（阿里提出了 residual embedding 的概念，希望把一个向量用中心向量和残差向量的形式去表示，以达到同一类别向量簇内高度聚集的目的。谷歌则希望对 embedding 的编码空间进行优化，简单来说就是为更高频更有效的特征分配更多的编码位置，反之则分配更少的编码位置）
表示：MF Seq embedding Graph Embedding 
特征抽取：DNN CNN RNN Transformer
融合：拼接 线性组合 attention
交叉：bit-wise element-wise vector-wise 高阶
优化：交叉方式、表示方式、结构

3. 概率校准
首先对采样进行校准，校准的公式在sigmoid的入参中加入了ln(r），r为负采样率
logloss MSE误差

4. 冷启动

5. 样本增广
样本融合、smote插值、gan样本增广（WGAN即基于W距离的GAN）、半监督学习的方法

6. 延迟转化

7. 参数自动寻优
（CEM、遗传算法）

8. 特征交叉
FM KFM DeepFM
NFM DeepNFM
DCN-v1/v2/M Cross AutoInt


9. 重排与多样性
强化学习DQN

10. ctr模型
两大优化范式：MLP结构优化、embedding特征交叉优化、embedding运算优化
内机：MF FM SVD++ IPNN
外积：ONCF OPNN
马哈大：CIN, xdeepFM NNCF
双线性：FiBiNET

Bit-wise: WDL DeepFM DCN
Ele-wise: CF NFM
Vec-wise FNN PNN CIN xdeepFM
Gp-wise: Gwen

拼接：YouTube
注意力：ACF AFM DIN DIEN Autoint FiBinet GAT
共享：deepFM DSSM
融合：图、文、kg

PNN：广告与用户embedding交叉

11. 召回
共线性、向量化、深度表征、多模态召回（3DCNN+VGGish+Attention\MV+DNN）


12. 智能创意组合
广告投放过程中，根据实际的投放效果，选择最佳的素材组合，关闭其他组合。智能创意组合，就是为了解决广告主的这个需求而设计的产品。
创意组合生成网络


13. 序列推荐
数据特性和挑战：
  Long： higher-order sequential dependencies（(1)基于高阶马尔科夫链方法的建模[4]；（2）基于RNN的方法）、long-term sequential dependencies（引入LSTM或GRU-based的模型、混合模型）
  with a Flexible Order：cnn解决
  with Noise：引入attention [9]或者memory networks[10]
  Heterogeneous Relations：基于Mixture models的方法
  Hierarchical Structures：the hierarchical structure between meta data and user-item interactions、the hierarchical structure between subsequences and user-item interactions。包括hierarchical embedding models[14],hierarchical RNN[15],hierarchical attention networks[16]将历史子序列合并到顺序依赖学习中，以构建更强大的SRSs

标准序列推荐：
  频繁模式：
  Markov Chain：FPMC[12]、Fossil[13]、潜在马尔可夫嵌入；一方面，由于当前交互只依赖于一个或多个最近的交互的马尔可夫性，RSs只能捕获短期的依赖，而忽略了长期的依赖。另一方面，它们只能捕获逐点依赖，而忽略了用户-商品交互的集体依赖
  FM类：很容易受到观测数据稀疏性的影响，因而无法得到理想的推荐效果。
  Embedding：简单、高效、有效
  Pooling：YoutubeDNN, 
  RNN：GRU4Rec[2]、RRN[14]、HRNN[15]、RNN，LSTM和GRU、层次RNN。1. RNN过于强烈地假设序列中的任何相邻交互都是有依赖关系的，因此很容易「产生错误依赖」，而在现实世界中可能不是这种情况，因为序列中通常存在不相关或噪声交互；2. 它可能只捕获逐点(point-wise)依赖，而忽略集体(collective)依赖（例如，多个交互协同影响下一个交互）
  CNN：3D-CNN[16]、Caser[3]、HierTCN[17]、TextCNN将CNN引入了序列建模，Caser中指出现在的Markov chain models只能建模point-level sequential patterns，不能建模union-level patterns，而CNN可以很好的解决这个问题, 学习区域间的模式而不是交互间的关系，因此基于CNN的SRSs可以在一定程度上弥补基于RNN的SRSs的上述缺点。然而，「由于CNN中使用的卷积核的大小有限基于CNN的SRSs不能有效地捕获长期依赖关系。」
  GNN：通常，有向图首先建立在序列数据的基础上，将每个交互作为图中的一个节点，同时将每个序列映射到一条路径。然后，在图上学习用户或商品的嵌入，从而在整个图上嵌入更复杂的关系。为可解释性推荐提供了一个很好的角度。
  Memory Network：当序列很长时可能会遗忘一些过去的交互，RUM[6]引入了用户记忆模块，来存储序列交互的信息, 通过引入外部内存矩阵，直接捕获用户项交互与下一个交互之间的依赖关系。
  Attention/Transformer：SASRec[4]、DIN、Bert4Rec[7]、SSE-PT[18]。强调序列中那些真正相关和重要的交互，而淡化那些与下一次交互无关的交互。它们被广泛地整合到浅层网络[9]和RNN[16]中，以处理带有噪声的交互序列
  Mixture models：将擅长捕获不同依赖关系的不同模型结合起来，以增强整个模型捕获各种依赖关系的能力
  对比学习：
长短期序列推荐：长期交互和短期交互对用户当前兴趣可能有着不同的影响，SHAN将用户行为分为长期的和短期的，使用层次注意力网络进行建模。
多兴趣表示的序列推荐：用户的兴趣偏好通常是多个方面的。
多行为序列推荐：用户通常有多种不同的行为序列

序列推荐中最关键的信息有两点，第一个是序列中item之间的关联性，第二个是user的personalization信息。除了这两点，还可以建立模型去学习结构信息，比如一些层级（hierarchy）信息，又或者是具体的时间（temporal）信息。能够把多种信息利用好，就能够完成序列推荐的任务

未来方向：Cross-domain、Interactive multi-time step、Social-aware、Context-aware 

## 参考文献：

[1] Deep Neural Networks for YouTube Recommendations. Recsys2016.
[2] Session-based Recommendations with Recurrent Neural Networks. ICLR2016.
[3] Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. WSDM2018.
[4] Self-Attentive Sequential Recommendation. ICDM2018.
[5] Deep Interest Network for Click-Through Rate Prediction. KDD2018.
[6] Sequential Recommendation with User Memory Networks. WSDM2018.
[7] BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. CIKM2019.
[8] Sequential Recommender System based on Hierarchical Attention Networks. IJCAI2018.
[9] Controllable Multi-Interest Framework for Recommendation. KDD2020.
[10] Incorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation. SIGIR2021.
[11] Disentangled Self-Supervision in Sequential Recommenders. KDD2020.
[12] Factorizing Personalized Markov Chains for Next-Basket Recommendation. WWW2010.
[13] Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation
[14] RecurrentRecommender Networks
[15] Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks
[16] 3D convolutional networks for session-based recommendation with content features
[17] Hierarchical temporal convolutional networks for dynamic recommender systems
[18] SSE-PT: Sequential Recommendation Via Personalized Transformer
Sequential Recommender Systems: Challenges, Progress and Prospects

Personalized news recommendation with context trees.
Factorizing personalized markov chains for next-basket recommendation
General factorization framework for context-aware recommendations.
Fusing similarity models with markov chains for sparse sequential recommendation.
Session-based recommendations with recurrent neural networks.
Towards neural mixture recommender for long range dependent user sequences
A simple convolutional generative network for next item recommendation.
Personalized top-n sequential recommendation via convolutional sequence embedding.
Attentionbased transactional context embedding for next-item recommendation.
Sequential recommendation with user memory networks.
Recommendation through mixtures of heterogeneous item relationships
Modeling multi-purpose sessions for nextitem recommendations via mixture-channel purpose routing networks.
Parallel recurrent neural network architectures for feature-rich session-based recommendations
Learning hierarchical representation model for next basket recommendation.
Personalizing session-based recommendations with hierarchical recurrent neural networks.
Sequential recommender system based on hierarchical attention networks.
Effective next-items recommendation via personalized sequential pattern mining
Personalized news recommendation with context trees.
Personalized ranking metric embedding for next new poi recommendation.
Learning hierarchical representation model for next basket recommendation.
Translation-based recommendation: A scalable method for modeling sequential behavior
Improving sequential recommendation with knowledge-enhanced memory networks     


